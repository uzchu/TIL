# SVM (서포트벡터머신)

> 서로 다른 분류에 속한 **데이터 간에 간격이 최대가 되는 선 또는 평면**을 찾아 이를 기준으로 데이터를 분류하는 모델



##### 초평면

: 유사한 그룹끼리 분류하는 칸막이

- 2차원에서는 선, 3차원에서는 평면
- 선형 분리 가능이 아닌 경우에도 적용이 가능



**>> 최대 마진 초평면(Maximum Margin Hyperplane; MMH)을 찾는것이 SVM의 핵심**



- 선형분리 가능 데이터

  - 각 그룹의 경계를 Convex Hull이라고 함. 이 때, MMH는 Convex Hull 사이의 가장 짧은 선에 대한 수직 이등분선

    

![image](https://user-images.githubusercontent.com/58683097/71445462-5cc3d080-275d-11ea-982e-a35f51e54160.png)

- 선형분리 불가능 데이터

  - 왼쪽 그림을 보면 데이터가 선형 분리가능한 상태
  - 왼쪽 상태에서 오른쪽 상태로 변환하는(새로운 데이터 공간으로 맵핑 (Mapping)) 함수를 커널 함수라고 하며, 데이터 공간 변환을 위해 다양한 커널 함수가 사용됨
  - 왼쪽그림은 위에서 본 그림, 오른쪽 그림은 지면에서 본 그림

  ![](https://user-images.githubusercontent.com/58683097/71445516-d9ef4580-275d-11ea-896e-909d28867731.png)

**>>** 시각에 따라 분리가능한 형태로 변환가능함을 이용해 데이터에 새로운 차원 추가 (커널트릭)

- 커널트릭?
  - 주어진 데이터를 적절한 고차원으로 옮긴 뒤 변환된 차원에서 SVM을 사용해 초평면을 찾는 것
  - 실제로 데이터를 고차원으로 변환하는 대신 고차원에서 벡터간 내적 계산을 했을 때와 같은 값을 반환하는 함수들을 사용함

- 커널함수

  : SVM 모델의 핵심수식은 **벡터 간 내적계산**
  - 커널 특징

    1) x와 y가 동일한 벡터일 때 가장 큼

    2) 두 벡터간 거리가 멀어질수록 작아짐

    **>>** 표본 데이터간의 유사도 측정하는 기준으로 볼 수도 있음

  - 대표적인 커널함수

    - 다항커널 : **입력의 모든차원의 조합인 공간**에서 내적을 계산한 것과 같은 결과 반환
    - 가우시안 커널 : **무한 차원**으로 데이터를 옮긴 뒤 그곳에서 내적을 계산한 것과 같은 결과 반환



-  SVM 장단점

| 장점                            | 단점                                                         |
| ------------------------------- | ------------------------------------------------------------ |
| 범주, 수치예측 문제에 사용가능  | 최적모델을 찾기위해 커널과 모델에 <br />매개변수의 여러가지 조합 테스트 필요 |
| 노이즈 영향 적고 과적합 잘 안됨 | 예제 개수와 속성수가 많으면 훈련 느림                        |
| 신경망보다 사용하기 쉬움        | 해석하기 어려움, 블랙박스                                    |
| 높은 정확도, 높은 프로필        |                                                              |



- 사용 패키지 ( in R)

  - e1071 (libsvm 사용 가능)

  - kernlab (가우시안 커널을 기본으로 사용)

  

- SVM 파라미터 튜닝

  - 교차검증 활용한 방법

  - SVM패키지가 제공하는 파라미터 튜닝 기능 활용한 방법

    - e1071 : tune() 활용해 최적 파라미터 값 추출

  - SVM 파라미터

    - gamma(r) : 결정경계의 곡률을 조정 (숫자가 낮을 수록 과적합 가능성이 줄고 일반화 가능성 증가, but 너무 작으면 과소적합 가능)
    - cost : 과적합 막는 정도 (숫자가 낮을 수록 과적합 가능성이 줄고 일반화 가능성 증가, but 너무 작으면 과소적합 가능)

    **>>** 적정값 찾는 것이 중요 (노가다..)