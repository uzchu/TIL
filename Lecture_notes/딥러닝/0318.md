필터가 W에 해당

cnn에서는 convolution result of channel을 feature map으로 걍 합산함

원래 차원이 축소되어서 패딩을 해줌

(어제 코드에선 패딩 없음)



feature map = activation map



activation map은 relu를 거친 맵



max pooling/ average pooling 두가지가 있지만, max pooling이 성능이 훨~씬 좋음



max pooling에서 출력 사이즈는 filter 사이즈로 나누면 됨



ex) 72 * 72 를 3*3으로 했으면, 24\*24가 됨

46*46 을 2\*2로 하면, 23\*23



