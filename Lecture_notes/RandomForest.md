# RandomForest (랜덤포레스트)

> 의사결정나무를 여러개 모아놓은 숲 (단, 랜덤으로 숲을 구성)
>
> 앙상블 학습은 주어진 데이터로부터 여러 개의 모델을 학습한 다음, 예측시 여러 모델의 예측 결과들을 종합해 사용하여 정확도를 높이는 기법
>
> 랜덤 포레스트는 앙상블 학습 기법 중 **배깅**을 사용



- 데이터의 일부를 복원 추출(Bootstrap)로 꺼내고 해당 데이터에 대해서만 의사 결정 나무를 만드는 방식
- 각각 다른 관점의 트리를 생성 (약한 분류기)
- 병렬구조(Aggregating)로 트리를 생성하여 동시에 보고 제일 많이 추천받은 순으로(투표방식) 변수를 추출해서 모델을 생성 (강한 분류기)

- 7:3, 8:2, 9:1 등의 비율로 train 데이터와 test데이터로 나눈 뒤 train데이터를 이용해 모형을 만들고 test데이터에서 새로운 데이터를 모형에 넣어 예측함
- train데이터를 추출하면서 예외된 부분인 OOB는 에러율을 파악용(유효성검사용)으로 씀 (새로운 데이터를 넣기 전 미리 체크하는 개념)



### randomforest 결과볼 때

>  행이 예측치, 열이 실측치

- MeanDecreaseAccuracy : 정확도를 개선 수치 (숫자 높을수록 더 중요)
- MeanDecreaseGini : 불순도를 개선 수치 (숫자 높을수록 더 중요)

=> 변량이 뭐가 중요한지 뽑아내는 것이 중요하고 중요도의 순서는 딱히 중요하지 않음. 적정 수준의 커트라인은 필요하지만 정해진 것이 없기 때문에 여러번 반복 수행해야함



#### 부스팅

- 직렬구조로 트리 생성 (순차 有)
- 오류가 높은 쪽(경계선 근처)의 학습량을 늘림
- 즉, 오류율이 높은 쪽에 가중치를 더 두어서 다음 번 모델을 만들 때 오류율이 높은 데이터들이 많이 들어오게 함
- Ada boosting (오류율 개선) 대표적

